{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Importing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/yunzheyu/Desktop/DS340/Project/DataSets'\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [f for f in os.listdir(directory) if f.endswith('.csv')]\n",
    "\n",
    "cleaned_data = []  # This will store all the cleaned DataFrames to be combined later\n",
    "\n",
    "for file in csv_files:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    \n",
    "    # Load the dataset\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # Filter to include only rows where the Event column is 'SBD' and Equipment is 'Raw'\n",
    "    sbd_raw_data = data[(data['Event'] == 'SBD') & (data['Equipment'] == 'Raw')]\n",
    "    \n",
    "    # Drop specified columns\n",
    "    columns_to_drop = [\n",
    "        'AgeClass', 'BirthYearClass', 'WeightClassKg', 'Squat4Kg', 'Bench4Kg', 'Deadlift4Kg',\n",
    "        'Wilks', 'Glossbrenner', 'Goodlift', 'Country', 'State', 'MeetCountry', \n",
    "        'MeetState', 'MeetTown', 'Federation', 'ParentFederation', 'MeetName'\n",
    "    ]\n",
    "    sbd_raw_data = sbd_raw_data.drop(columns=columns_to_drop, errors='ignore')\n",
    "    \n",
    "    # Drop rows where the Place column contains 'DQ', 'NS', or 'G'\n",
    "    sbd_raw_data = sbd_raw_data[~sbd_raw_data['Place'].isin(['DQ', 'NS', 'G'])]\n",
    "\n",
    "    # Drop rows where the Tested column is empty\n",
    "    sbd_raw_data = sbd_raw_data.dropna(subset=['Tested'])\n",
    "    \n",
    "    # Save the cleaned data to a new CSV file\n",
    "    cleaned_file_path = os.path.join(directory, f'cleaned_{file}')\n",
    "    sbd_raw_data.to_csv(cleaned_file_path, index=False)\n",
    "    \n",
    "    # Append the cleaned data to the list for later combination\n",
    "    cleaned_data.append(sbd_raw_data)\n",
    "\n",
    "# Concatenate all data into a single DataFrame\n",
    "combined_cleaned_data = pd.concat(cleaned_data, ignore_index=True)\n",
    "combined_cleaned_data.to_csv('combined_cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with missing age.\n",
    "\n",
    "Some Atheletes do have provide their ages. So, we will use the last known competition date and last known age to estimate the missing age value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set a DataFrame with multiple columns to the single column Estimated_Age",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(estimated_age)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mSeries(results, index\u001b[38;5;241m=\u001b[39mgroup\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m---> 33\u001b[0m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEstimated_Age\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(apply_age_estimation)\u001b[38;5;241m.\u001b[39mreset_index(level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Now handling other computations like Competition Frequency and Year-over-Year Performance\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Competition Frequency\u001b[39;00m\n\u001b[1;32m     38\u001b[0m competition_frequency \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMeetName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/core/frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3948\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[1;32m   3949\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m-> 3950\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3951\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   3952\u001b[0m     is_list_like(value)\n\u001b[1;32m   3953\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[1;32m   3954\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[1;32m   3955\u001b[0m ):\n\u001b[1;32m   3956\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[1;32m   3957\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/pandas/core/frame.py:4104\u001b[0m, in \u001b[0;36mDataFrame._set_item_frame_value\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 4104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set a DataFrame with multiple columns to the single \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4106\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4107\u001b[0m     )\n\u001b[1;32m   4109\u001b[0m \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m value[value\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot set a DataFrame with multiple columns to the single column Estimated_Age"
     ]
    }
   ],
   "source": [
    "# Ensure the 'Date' column is in datetime format\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Sort data by athlete's name and date of competition\n",
    "data = data.sort_values(by=['Name', 'Date'])\n",
    "\n",
    "# Function to estimate ages based on previous known ages and competition dates\n",
    "def estimate_age(row, last_known_age, last_known_date):\n",
    "    if pd.notnull(row['Age']):\n",
    "        return row['Age'], row['Date']\n",
    "    elif pd.notnull(last_known_age) and pd.notnull(last_known_date):\n",
    "        # Calculate the year difference\n",
    "        year_difference = row['Date'].year - last_known_date.year\n",
    "        # Estimate the current age\n",
    "        estimated_age = last_known_age + year_difference\n",
    "        return estimated_age, row['Date']\n",
    "    return None, row['Date']\n",
    "\n",
    "# Apply a groupby operation to carry forward the age estimation\n",
    "last_known_age = None\n",
    "last_known_date = None\n",
    "\n",
    "def apply_age_estimation(group):\n",
    "    global last_known_age, last_known_date\n",
    "    last_known_age, last_known_date = None, None  # Reset for each group\n",
    "    results = []\n",
    "    for index, row in group.iterrows():\n",
    "        estimated_age, last_known_date = estimate_age(row, last_known_age, last_known_date)\n",
    "        last_known_age = estimated_age if pd.notnull(estimated_age) else last_known_age\n",
    "        results.append(estimated_age)\n",
    "    return pd.Series(results, index=group.index)\n",
    "\n",
    "data['Estimated_Age'] = data.groupby('Name').apply(apply_age_estimation).reset_index(level=0, drop=True)\n",
    "\n",
    "# Now handling other computations like Competition Frequency and Year-over-Year Performance\n",
    "\n",
    "# Competition Frequency\n",
    "competition_frequency = data.groupby('Name')['MeetName'].count().reset_index()\n",
    "competition_frequency.rename(columns={'MeetName': 'CompetitionCount'}, inplace=True)\n",
    "\n",
    "# Year-over-Year Performance Improvements\n",
    "# Calculate the best total weight per year per athlete\n",
    "data['CompetitionYear'] = data['Date'].dt.year\n",
    "yearly_performance = data.groupby(['Name', 'CompetitionYear'])['TotalKg'].max().reset_index()\n",
    "# Calculate year-over-year improvement\n",
    "yearly_performance['YoY_Improvement'] = yearly_performance.groupby('Name')['TotalKg'].diff()\n",
    "\n",
    "# Merge these calculations back to the main dataset\n",
    "data = data.merge(competition_frequency, on='Name', how='left')\n",
    "data = data.merge(yearly_performance[['Name', 'CompetitionYear', 'YoY_Improvement']], on=['Name', 'CompetitionYear'], how='left')\n",
    "\n",
    "# Print the head of the dataset to verify results\n",
    "print(data[['Name', 'Date', 'Age', 'Estimated_Age']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
