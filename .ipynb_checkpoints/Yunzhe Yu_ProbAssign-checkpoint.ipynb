{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gfrqSXdehYl"
   },
   "source": [
    "# Applied Probability Homework - 60 points total\n",
    "\n",
    "This file needs the accompanying file train.tsv.\n",
    "\n",
    "## Part 1:  Bayesian Tomatoes (25 points)\n",
    "\n",
    "In this part of the assignment, you'll implement the final part of a Naive Bayes classifier that performs sentiment analysis on sentences from movie reviews.  Upload and read the train.tsv file that contains sentences and phrases that have been rated 0 to 4 for sentiment ranging from very negative to very positive.  We'll only be working with the full sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QLls4yAXC2xK",
    "outputId": "94e5c371-10e0-40f2-a860-734431860498"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/yunzheyu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')  # Data for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1VnrdxYu6HXD"
   },
   "outputs": [],
   "source": [
    "with open('train.tsv', 'r') as textfile:\n",
    "  ratings_data = textfile.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "UjQUhiDhAZP2"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenize(sentence):\n",
    "    \"\"\" Returns list of tokens (strings) from the sentence.\n",
    "\n",
    "    Sets to lowercase and runs NLTK tokenizer.\n",
    "\n",
    "    Args:\n",
    "        sentence (string):  the string to tokenize\n",
    "    \"\"\"\n",
    "    return [t.lower() for t in word_tokenize(sentence)]\n",
    "\n",
    "class ModelInfo:\n",
    "    \"\"\" Contains all counts from the data necessary to do Naive Bayes or babbling.\n",
    "\n",
    "    Attributes:\n",
    "        word_counts (List[Dict[string,int]]):  counts of tokens, indexed by class\n",
    "        sentiment_counts (List[int]):  counts of sentences with each sentiment\n",
    "        total_words (List[int]):  counts of words in each sentiment\n",
    "        total_examples (int):  total sentence count\n",
    "        bigram_counts (List[Dict[string, int]]):  counts of bigrams (two-word sequences)\n",
    "                for each sentiment, indexed by string 'word1_word2'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.word_counts = [{}, {}, {}, {}, {}]\n",
    "        self.sentiment_counts = [0, 0, 0, 0, 0]\n",
    "        self.total_words = [0, 0, 0, 0, 0]\n",
    "        self.total_examples = 0\n",
    "        self.bigram_counts = [{}, {}, {}, {}, {}]\n",
    "        self.trigram_counts = [{}, {}, {}, {}, {}]\n",
    "\n",
    "\n",
    "    def update_word_counts(self, sentence, sentiment):\n",
    "        \"\"\" Consume a sentence and update all counts.\n",
    "\n",
    "        To \"tokenize\" the sentence we'll make use of NLTK, a widely-used Python natural language\n",
    "        processing (NLP) library.  This will handle otherwise onerous tasks like separating periods\n",
    "        from their attached words.  (Unless the periods are decimal points ... it's more complex\n",
    "        than you might think.)  The result of tokenization is a list of individual strings that are\n",
    "        words or their equivalent.\n",
    "\n",
    "        Args:\n",
    "            sentence (string):  The example sentence.\n",
    "            sentiment (int):  The sentiment label.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the relevant dicts for the sentiment\n",
    "        s_word_counts = self.word_counts[sentiment]\n",
    "        tokens = tokenize(sentence)\n",
    "        for i in range(len(tokens)):\n",
    "            self.total_words[sentiment] += 1\n",
    "            s_word_counts[tokens[i]] = s_word_counts.get(tokens[i], 0) + 1\n",
    "            if i < len(tokens) - 1:\n",
    "                bigram = tokens[i] + '_' + tokens[i+1]\n",
    "                self.bigram_counts[sentiment][bigram] = self.bigram_counts[sentiment].get(bigram, 0) + 1\n",
    "            if i < len(tokens) - 2:\n",
    "                trigram = tokens[i] + '_' + tokens[i+1] + '_' + tokens[i+2]\n",
    "                self.trigram_counts[sentiment][trigram] = self.trigram_counts[sentiment].get(trigram,0) + 1\n",
    "\n",
    "FIRST_SENTENCE_NUM = 1\n",
    "\n",
    "def get_models(ratings_data):\n",
    "    \"\"\"Returns a model_info object, consuming a string for examples.\"\"\"\n",
    "    next_fresh = FIRST_SENTENCE_NUM\n",
    "    info = ModelInfo()\n",
    "    for line in ratings_data.splitlines():\n",
    "        if line.startswith(\"---\"):\n",
    "            return info\n",
    "        fields = line.split(\"\\t\")\n",
    "        try:\n",
    "            sentence_num = int(fields[1])\n",
    "            if sentence_num <= next_fresh:\n",
    "                continue\n",
    "            next_fresh += 1\n",
    "            sentiment = int(fields[3])\n",
    "            info.sentiment_counts[sentiment] += 1\n",
    "            info.total_examples += 1\n",
    "            info.update_word_counts(fields[2], sentiment)\n",
    "        except ValueError:\n",
    "            # Some kind of bad input?  Unlikely with our provided data\n",
    "            continue\n",
    "    return info\n",
    "\n",
    "model_info = get_models(ratings_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-T9BI1RFCOK"
   },
   "source": [
    "**(1, 20 points)** Complete naive_bayes_classify(), below.  It should take a ModelInfo object and use the counts stored therein to give the most likely class according to a Naive Bayes calculation, and the log likelihood of that class.  For priors on the sentiment, use the actual frequencies with which each sentiment is used.  Notice that there are 5 different classes to compare.  Use the OUT_OF_VOCAB_PROB constant for any tokens that haven't been seen for a particular sentiment in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hVH8TO7dDZlX"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "CLASSES = 5\n",
    "OUT_OF_VOCAB_PROB = 0.0000000001\n",
    "\n",
    "\"\"\" naive_bayes_classify:  takes a ModelInfo containing all counts necessary for classsification\n",
    "    and a String to be classified.  Returns a number indicating sentiment and a log probability\n",
    "    of that sentiment (two comma-separated return values).\n",
    "\"\"\"\n",
    "def naive_bayes_classify(info, sentence):\n",
    "    \"\"\" Use a Naive Bayes model to return sentence's most likely classification and the log prob.\n",
    "\n",
    "    Args:\n",
    "        info (ModelInfo):  a ModelInfo containing the counts from the training data\n",
    "        sentence (string):  the test sentence to classify\n",
    "\n",
    "    Returns:\n",
    "        int for the best sentiment\n",
    "        float for the best log probability (unscaled, just log(prior * product of cond. probs))\n",
    "    \"\"\"\n",
    "      # Tokenize the sentence\n",
    "    tokens = tokenize(sentence)\n",
    "    \n",
    "    # Initialize variables to store the best class and its log probability\n",
    "    best_class = None\n",
    "    best_log_prob = -float('inf')\n",
    "\n",
    "    # Iterate over each class (sentiment)\n",
    "    for c in range(CLASSES):\n",
    "        # Calculate the log prior: log(P(c)) = log(sentiment_counts[c] / total_examples)\n",
    "        log_prior = math.log(info.sentiment_counts[c] / info.total_examples)\n",
    "\n",
    "        # Initialize the log likelihood: log(P(word|c))\n",
    "        log_likelihood = 0\n",
    "\n",
    "        # Calculate the log likelihood for each word in the sentence\n",
    "        for word in tokens:\n",
    "            word_count = info.word_counts[c].get(word, 0)\n",
    "            if word_count == 0:\n",
    "                # Use OUT_OF_VOCAB_PROB for words not in the vocabulary\n",
    "                log_likelihood += math.log(OUT_OF_VOCAB_PROB)\n",
    "            else:\n",
    "                # Calculate the probability: P(word|c) = count(word, c) / total_words(c)\n",
    "                prob_word_given_class = word_count / info.total_words[c]\n",
    "                log_likelihood += math.log(prob_word_given_class)\n",
    "\n",
    "        # Calculate the total log probability for the class: log(P(c)) + sum(log(P(word|c)))\n",
    "        total_log_prob = log_prior + log_likelihood\n",
    "\n",
    "        # Update the best class and its probability if this class is better\n",
    "        if total_log_prob > best_log_prob:\n",
    "            best_class = c\n",
    "            best_log_prob = total_log_prob\n",
    "\n",
    "    return best_class, best_log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "laPUyW3mGDnR",
    "outputId": "e405a013-8e37-491a-fe51-a130053597ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, -25.947997071867018)\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "print(naive_bayes_classify(model_info, \"I hate this movie\")) # Should return 0, -25.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0nm828N8VC_",
    "outputId": "e3a515f7-e649-4228-e65b-009403943fb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, -22.9049498861873)\n"
     ]
    }
   ],
   "source": [
    "print(naive_bayes_classify(model_info, \"A joyous romp\"))    # Should return 4, -22.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uLlIdvFU8NNF",
    "outputId": "917f241e-4a55-4d29-b9b1-426213a2be68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, -24.32724312507062)\n"
     ]
    }
   ],
   "source": [
    "print(naive_bayes_classify(model_info, \"notaword\")) # Should return 3, -24.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7CXn5RzS5A7s"
   },
   "source": [
    "**2, 5 points)** Naive Bayes is sometimes called a \"linear\" classifier; let's explore why.  Suppose I have two classes $C_1$ and $C_2$ and two observable features A and B; each feature can take on 3 values.  Feature A's conditional distribution is [1/2, 1/4, 1/4] for class 1, [1/4, 1/4, 1/2] for class 2.  Feature B's conditional distribution is [1/4, 1/2, 1/4] for class 1, [1/2, 1/4, 1/4] for class 2.  The two classes each have a prior of 1/2.  Given boolean values (i.e. valued 0 or 1) $a_0$, $a_1$, $a_2$ and $b_0$, $b_1$, $b_2$ to represent the observations of feature A and B, derive an equation for each class that gives the log likelihood of that class given the observations.  (Use base 2 for your logs to make the equations simpler.)  Then, use these log likelihoods to come up with a linear inequality (a weighted sum of $a_0, \\ldots, b_2$ that is compared to a constant) that decides whether an example belongs to class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8M11qIO25A7u"
   },
   "source": [
    "### Answer\n",
    "### Naive Bayes Formula for Log Likelihood\n",
    "For a class $( C )$, the log likelihood given observations is:\n",
    "$$\n",
    "\\log P(C | \\text{observations}) = \\log P(C) + \\sum \\log P(\\text{feature value} | C)\n",
    "$$\n",
    "Since we are using base 2 for logs, and the priors for each class are $( \\frac{1}{2} )$, the log prior $( \\log P(C) )$ for both classes is $( \\log_2(\\frac{1}{2}) = -1 )$.\n",
    "\n",
    "### Feature A and B Conditional Distributions\n",
    "- Feature A for $( C_1 ): (\\left[\\frac{1}{2}, \\frac{1}{4}, \\frac{1}{4}\\right])$, and for $( C_2 ): (\\left[\\frac{1}{4}, \\frac{1}{4}, \\frac{1}{2}\\right])$\n",
    "- Feature B for $( C_1 ): (\\left[\\frac{1}{4}, \\frac{1}{2}, \\frac{1}{4}\\right])$, and for $( C_2 ): (\\left[\\frac{1}{2}, \\frac{1}{4}, \\frac{1}{4}\\right])$\n",
    "\n",
    "### Log Likelihood Equations\n",
    "For class $( C_1 )$:\n",
    "$$\n",
    "\\log P(C_1 | a_0, a_1, a_2, b_0, b_1, b_2) = -1 + (a_0 \\cdot \\log_2(\\frac{1}{2}) + a_1 \\cdot \\log_2(\\frac{1}{4}) + a_2 \\cdot \\log_2(\\frac{1}{4})) + (b_0 \\cdot \\log_2(\\frac{1}{4}) + b_1 \\cdot \\log_2(\\frac{1}{2}) + b_2 \\cdot \\log_2(\\frac{1}{4}))\n",
    "$$\n",
    "\n",
    "For class $( C_2 )$:\n",
    "$$\n",
    "\\log P(C_2 | a_0, a_1, a_2, b_0, b_1, b_2) = -1 + (a_0 \\cdot \\log_2(\\frac{1}{4}) + a_1 \\cdot \\log_2(\\frac{1}{4}) + a_2 \\cdot \\log_2(\\frac{1}{2})) + (b_0 \\cdot \\log_2(\\frac{1}{2}) + b_1 \\cdot \\log_2(\\frac{1}{4}) + b_2 \\cdot \\log_2(\\frac{1}{4}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Z-tE4ZAemNE"
   },
   "source": [
    "## Part 2:  Bigram and Trigram Beam Search Babblers (35 points)\n",
    "\n",
    "Even complex neural networks like ChatGPT can use search to think a little bit ahead, and choose options that will work out better later on down the line.  Beam search is commonly used for this purpose.\n",
    "\n",
    "The steps below refer to *bigrams*, which are sequences of two words (like \"I see\"), and *trigrams*, which are sequences of 3 words (\"I see you\").  A bigram model of language tracks the likelihood of one word following another (P(\"see\" | \"I\")).  A trigram model tracks the likelihood of one word following two other words (P(\"you\" | \"I see\")).  Both were highly influential models of language in natural language processing, but running them in the \"forward direction\" for production reveals their limitations.  (ChatGPT effectively conditions on *all* previous words in the prompt and response so far.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 (10 points):  Create a function \"babble\" that takes as input a starting word *start*, a sentiment number (0-4), a ModelInfo object, and a number of additional words to babble, n.  Start with the starting word, and for n steps, add a space to that string followed by the single most likely word in terms of conditional probability $P(word_i | word_{i-1}, sentiment)$, which you can compute from the ModelInfo.  Return the string you've created.  (Note that bigram counts are stored with key 'word1_word2'.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"acting , and the movie . ' and the movie .\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def babble(start, sentiment, model_info, n):\n",
    "    current_word = start.lower()\n",
    "    sentence = start\n",
    "\n",
    "    for _ in range(n):\n",
    "        next_word = None\n",
    "        max_count = -1  # Initialize with -1 to ensure any count is considered\n",
    "        bigram_prefix = current_word + '_'\n",
    "\n",
    "        # Find the most likely next word\n",
    "        for bigram, count in model_info.bigram_counts[sentiment].items():\n",
    "            if bigram.startswith(bigram_prefix):\n",
    "                # Only consider the bigram if it's strictly more common\n",
    "                if count > max_count:\n",
    "                    max_count = count\n",
    "                    next_word = bigram[len(bigram_prefix):]\n",
    "\n",
    "        if next_word:\n",
    "            sentence += ' ' + next_word\n",
    "            current_word = next_word\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return sentence\n",
    "babble('acting', 0, model_info, 10) # Expect \"acting , and the movie . ' and the movie .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"acting , and the film . ' . ' . '\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "babble('acting', 4, model_info, 10) # Expect \"acting , and the film . ' . ' . '\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 (15 points):  Now, write a similar function beam_babble(start, sentiment, info, n, k) that performs beam search with beam size k from start word \"start\" out to n steps, and returns the most likely sequence.  This should still use the conditional probabilities $P(word_i | word_{i-1}, sentiment)$ that you used for the previous babbler.\n",
    "\n",
    "The solution made use of the following helper functions:  make_new_seq(old_words, new_word, old_prob, bigram_prob), which took the old_words and old_prob from an existing sequence and updated it with the new word and bigram probability; bigram_prob(info, sentiment, prev_word, word), which used the word at the end of the sequence and the new word to calculate $P(word_i | word_{i-1}, sentiment)$; and top_k(seqs, k), which returned the top k sequences of a list of (wordlist, prob) entries representing sequences.  You can have top_k's code, and the tests for the others are left here if you want them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "# TODO def beam_babble(start, sentiment, info, n, k):\n",
    "\n",
    "# Optional TODO def make_new_seq(old_words, new_word, old_prob, bigram_prob):\n",
    "                                         \n",
    "# Optional TODO def bigram_prob(info, sentiment, prev_word, word):\n",
    "\n",
    "def beam_babble(start, sentiment, info, n, k):\n",
    "    \"\"\"Generate text using beam search with a beam size of k, with error handling for empty word list.\"\"\"\n",
    "    start_word = start.lower()\n",
    "    initial_seq = ([start_word], 1)  # Starting with the initial word and probability 1\n",
    "    beam = [initial_seq]\n",
    "\n",
    "    for _ in range(n):\n",
    "        all_candidates = []\n",
    "\n",
    "        for seq in beam:\n",
    "            prev_word = seq[0][-1]  # Last word in the current sequence\n",
    "            expansions_found = False\n",
    "            words_list = list(info.word_counts[sentiment].keys())\n",
    "\n",
    "            # Check if words_list is not empty before proceeding\n",
    "            if words_list:\n",
    "                for word in words_list:\n",
    "                    bigram = prev_word + '_' + word\n",
    "                    if bigram in info.bigram_counts[sentiment]:\n",
    "                        new_prob = bigram_prob(info, sentiment, prev_word, word)\n",
    "                        if new_prob > 1e-5:  # Consider only probable bigrams\n",
    "                            new_seq = make_new_seq(seq[0], word, seq[1], new_prob)\n",
    "                            all_candidates.append(new_seq)\n",
    "                            expansions_found = True\n",
    "\n",
    "            # If no expansions are found, keep the current sequence (prevent empty beam)\n",
    "            if not expansions_found and len(seq[0]) < n:\n",
    "                # Add a low probability continuation to keep the sequence going\n",
    "                if words_list:\n",
    "                    dummy_next_word = words_list[0]\n",
    "                    new_seq = make_new_seq(seq[0], dummy_next_word, seq[1], 1e-5)\n",
    "                    all_candidates.append(new_seq)\n",
    "\n",
    "        # Keep only the top k sequences\n",
    "        beam = top_k(all_candidates, k)\n",
    "\n",
    "    # Return the highest probability sequence along with its probability\n",
    "    return max(beam, key=lambda x: x[1]) if beam else ([], 0)\n",
    "\n",
    "def top_k(seqs, k):\n",
    "    seqs.sort(key = lambda x : x[1], reverse=True)\n",
    "    return seqs[0:k]\n",
    "\n",
    "def bigram_prob(info, sentiment, prev_word, word):\n",
    "    bigram = f\"{prev_word}_{word}\"\n",
    "    bigram_count = info.bigram_counts[sentiment].get(bigram, 0)\n",
    "    prev_word_count = info.word_counts[sentiment].get(prev_word, 0)\n",
    "    \n",
    "    # If the bigram has been seen, calculate its probability normally\n",
    "    if bigram_count > 0:\n",
    "        return bigram_count / prev_word_count\n",
    "    # If the bigram has not been seen, return a small fixed probability\n",
    "    else:\n",
    "        return 1e-7\n",
    "\n",
    "\n",
    "def make_new_seq(old_words, new_word, old_prob, bigram_prob):\n",
    "    \"\"\"Update a sequence with a new word and probability\"\"\"\n",
    "    new_seq = old_words + [new_word]\n",
    "    new_prob = old_prob * bigram_prob\n",
    "    return new_seq, new_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['hello', 'there'], 0.5), (['hello', 'hello'], 0.3)]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "seqs = [(['hello', 'there'], 0.5), (['well', 'goodbye'], 0.2), (['hello', 'hello'], 0.3)]\n",
    "print(top_k(seqs, 2)) # Should be [(['hello', 'there'], 0.5), (['hello', 'hello'], 0.3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{}, {'hello_hello': 1, 'hello_goodbye': 1, 'goodbye_goodbye': 1}, {}, {}, {}]\n",
      "0.5\n",
      "0.5\n",
      "0.5\n",
      "1e-07\n"
     ]
    }
   ],
   "source": [
    "model_info = ModelInfo()\n",
    "model_info.update_word_counts('hello hello goodbye goodbye', 1)\n",
    "print(model_info.bigram_counts)\n",
    "print(bigram_prob(model_info, 1, 'hello', 'hello')) # Expect 0.5\n",
    "print(bigram_prob(model_info, 1, 'hello', 'goodbye')) # Expect 0.5\n",
    "print(bigram_prob(model_info, 1, 'goodbye', 'goodbye')) # Expect 0.5 (transition to goodbye or end)\n",
    "print(bigram_prob(model_info, 1, 'goodbye', 'hello')) # Not seen, expect tiny number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['hello', 'hello', 'goodbye'], 0.020000000000000004)\n"
     ]
    }
   ],
   "source": [
    "print(make_new_seq(['hello', 'hello'], 'goodbye', 0.2, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['acting',\n",
       "  'talents',\n",
       "  'wasting',\n",
       "  'away',\n",
       "  'inside',\n",
       "  'unnecessary',\n",
       "  'prologue',\n",
       "  ',',\n",
       "  'but',\n",
       "  'it',\n",
       "  \"'s\"],\n",
       " 5.982521449703316e-07)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "Expect\n",
    "(['acting',\n",
    "  'talents',\n",
    "  'wasting',\n",
    "  'away',\n",
    "  'inside',\n",
    "  'unnecessary',\n",
    "  'prologue',\n",
    "  ',',\n",
    "  'but',\n",
    "  'it',\n",
    "  \"'s\"],\n",
    " 5.982521449703316e-07)\n",
    "\"\"\"\n",
    "beam_babble('acting', 0, model_info, 10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'acting' in vocabulary for sentiment 0: True\n",
      "Some words in vocabulary for sentiment 0: ['hampered', '--', 'no', ',', 'paralyzed', 'by', 'a', 'self-indulgent', 'script', '...']\n"
     ]
    }
   ],
   "source": [
    "# Check if 'acting' is in the vocabulary for sentiment 0\n",
    "print(\"'acting' in vocabulary for sentiment 0:\", 'acting' in model_info.word_counts[0])\n",
    "\n",
    "# Optionally, print some of the vocabulary for sentiment 0 to inspect it\n",
    "print(\"Some words in vocabulary for sentiment 0:\", list(model_info.word_counts[0].keys())[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['acting',\n",
       "  'bond',\n",
       "  ';',\n",
       "  'i',\n",
       "  \"'ve\",\n",
       "  'ever',\n",
       "  'seen',\n",
       "  'before',\n",
       "  'swooping',\n",
       "  'aerial',\n",
       "  'shots'],\n",
       " 1.3664786392059117e-07)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Expect\n",
    "(['acting',\n",
    "  'bond',\n",
    "  ';',\n",
    "  'i',\n",
    "  \"'ve\",\n",
    "  'ever',\n",
    "  'seen',\n",
    "  'before',\n",
    "  'swooping',\n",
    "  'aerial',\n",
    "  'shots'],\n",
    " 1.3664786392059117e-07)\n",
    "\"\"\"\n",
    "beam_babble(\"acting\", 4, model_info, 10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 (10 points):  If the results still seem a little lackluster, it's because we're only conditioning on the previous word - it has no memory of what it was just saying.  We can do a little better at the expense of plagiarizing the text more often - by using \"trigrams\" to calculate $P(w_n | w_{n-2}, w_{n-1}, sentiment)$.  Rewrite your beam search code below to use trigrams.  The counts of how often triplets of words appear - $w_i \\wedge w_{i+1} \\wedge w_{i+2}$ - have already been stored in the ModelInfo object.  A trigram_prob() function similar to the previous problem step's bigram_prob() has some tests left here for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trigram_prob(info, sentiment, prev_word1, prev_word2, word):\n",
    "    trigram_key = f'{prev_word1}_{prev_word2}_{word}'\n",
    "    trigram_count = info.trigram_counts[sentiment].get(trigram_key, 0)\n",
    "    \n",
    "    # This should be the count of just 'prev_word1_prev_word2' bigram, not the sum of all bigrams.\n",
    "    prev_bigram_key = f'{prev_word1}_{prev_word2}'\n",
    "    prev_bigram_count = info.bigram_counts[sentiment].get(prev_bigram_key, 0)\n",
    "    \n",
    "    if trigram_count == 0:\n",
    "        return 1e-7  # A tiny probability for unseen trigrams\n",
    "    else:\n",
    "        return trigram_count / prev_bigram_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_babble_trigram(start, start2, sentiment, info, n, k):\n",
    "    initial_seq = ([start, start2], 1.0)  # Starting sequence with two words and probability 1\n",
    "    beam = [initial_seq]\n",
    "\n",
    "    for _ in range(n - 2):  # Generate n-2 more words\n",
    "        all_candidates = []\n",
    "\n",
    "        for seq, prob in beam:\n",
    "            prev_word1, prev_word2 = seq[-2], seq[-1]  # Last two words in the current sequence\n",
    "            expansions_found = False\n",
    "\n",
    "            for word in info.word_counts[sentiment].keys():\n",
    "                new_prob = trigram_prob(info, sentiment, prev_word1, prev_word2, word)\n",
    "                if new_prob > 0:  # Only consider valid expansions\n",
    "                    new_seq = seq + [word]\n",
    "                    all_candidates.append((new_seq, new_prob * prob))\n",
    "                    expansions_found = True\n",
    "\n",
    "            # If no valid expansions for this sequence, it's carried over without expansion\n",
    "            if not expansions_found:\n",
    "                all_candidates.append((seq, prob))\n",
    "\n",
    "        # Sort candidates by their probability and keep only the top k sequences\n",
    "        beam = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:k]\n",
    "\n",
    "    # Choose the sequence with the highest probability\n",
    "    best_seq, best_prob = max(beam, key=lambda x: x[1]) if beam else ([], 0)\n",
    "\n",
    "    # Normalize the final probability by the length of the sequence for fairness\n",
    "    normalized_prob = best_prob / len(best_seq) if best_seq else 0\n",
    "    return best_seq, normalized_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{}, {'hello_hello_hello': 1, 'hello_hello_goodbye': 1, 'hello_goodbye_goodbye': 1, 'goodbye_goodbye_goodbye': 2, 'goodbye_goodbye_hello': 1}, {}, {}, {}]\n",
      "0.5\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "model_info = ModelInfo()\n",
    "model_info.update_word_counts('hello hello hello goodbye goodbye goodbye goodbye hello', 1)\n",
    "print(model_info.trigram_counts)\n",
    "print(trigram_prob(model_info, 1, 'hello', 'hello', 'goodbye')) # Expect 0.5\n",
    "print(trigram_prob(model_info, 1, 'goodbye', 'goodbye', 'hello')) # Expect 0.33333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the',\n",
       "  'acting',\n",
       "  'is',\n",
       "  'amateurish',\n",
       "  ',',\n",
       "  'quasi-improvised',\n",
       "  'acting',\n",
       "  'exercise',\n",
       "  'shot',\n",
       "  'on'],\n",
       " 0.016666666666666666)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_babble_trigram('the', 'acting', 0, model_info, n=10, k=20)\n",
    "# Expect (['the','acting','is', 'amateurish', ',', 'quasi-improvised', 'acting', 'exercise', 'shot', 'on', 'ugly', 'digital'], 0.08333333333333333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the',\n",
       "  'acting',\n",
       "  'in',\n",
       "  'pauline',\n",
       "  'and',\n",
       "  'paulette',\n",
       "  'is',\n",
       "  'good',\n",
       "  'all',\n",
       "  'round'],\n",
       " 0.1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_babble_trigram('the', 'acting', 4, model_info, n=10, k=20) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to this line in the original train.tsv:  \"The acting in Pauline And Paulette is good all round, but what really sets the film apart is Debrauwer's refusal to push the easy emotional buttons.\"  We didn't intend for this copying to happen, but it just so happened that this word sequence was rare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnwYi9lob0B1"
   },
   "source": [
    "**When you're done, use \"File->Download .ipynb\" and upload your .ipynb file to Blackboard, along with a PDF version (File->Print->Save as PDF) of your assignment.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
