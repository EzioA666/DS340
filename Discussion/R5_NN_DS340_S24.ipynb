{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [https://playground.tensorflow.org](https://playground.tensorflow.org) and adjust the parameters of the model there to answer the following questions.\n",
    "\n",
    "1) With a single-hidden-layer neural network, what is the minimum number of hidden layer neurons necessary to faithfully classify the circle-surrounded-by-ring pattern?  Why is that?\n",
    "\n",
    "### A:\n",
    "Generally, at least three neurons might be needed: one to model the inner circle and two to outline the outer ring's boundaries. This setup allows the network to approximate the non-linear decision boundary between the circle and the ring. However, the exact number can vary based on the specific requirements for classification accuracy and the data's characteristics. Determining the optimal number of neurons often requires empirical testing and adjustment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) On the same dataset, describe how learning progresses with a learning rate of 3, compared to the previous default learning rate of 0.03."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Experimenting with more layers and the ReLU activation function, see whether you can train a network to classify the jelly-roll pattern (lower right) mostly correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe how to do a minimal neural network in Keras on the digits dataset.  (Note that these images are smaller than what you'd typically tackle in Keras.)\n",
    "Then try to follow the same steps to build a single-layer network that classifies the wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow.keras.optimizers\n",
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(data, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's generally good to normalize data, or make the values fall between 0 and 1, when dealing with neural networks.  We got lucky in not using this step with the digits learning early in this recitation.  255 is the maximum value of brightness in the data, so that's what we divide by."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_valid /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras wants the output to be in a vector form with a 1 where the answer is and 0's elsewhere; for example, 2 becomes [0,0,1,0,0,0,0,0,0,0].  This is handled by the to_categorical() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras requires declaring the kind of model, which is normally Sequential for basic classification tasks, followed by calling .add() on the model to add layers one at a time.   There are two layers of connections in a single-hidden-layer network:  input to hidden and hidden to output.  \"Dense\" is a layer type that is fully connected.  Its first argument is how many neurons are in the next layer.  We put 100 for the hidden layer to make it match the scikit-learn default, then 10 because there are 10 possible outputs (the digits 0-9).  input_shape is (64,) because the digits images are 8x8 and we flattened them into 64-element vectors.  A 'softmax' activation function is like a sigmoid activation function, but normalized so the outputs all sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='sigmoid', input_shape=(64,)))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the architecture is specified, we need to compile the model with information about what the loss is and how we will optimize to reduce that loss.  We'll choose mean squared error for the loss, and choose the somewhat fancy \"adam\" optimizer to minimize that loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit to data.  Here we specify a batch size, or the number of images to look at before making a single change to the model; and the number of epochs, which should be increased if it looks as though the model might still be improving when it finishes.  Verbose=1 lets us follow along with the learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-22 11:24:25.566575: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 33ms/step - loss: 0.0910 - accuracy: 0.0987 - val_loss: 0.0901 - val_accuracy: 0.1044\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0900 - accuracy: 0.1084 - val_loss: 0.0901 - val_accuracy: 0.0867\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0899 - accuracy: 0.1670 - val_loss: 0.0899 - val_accuracy: 0.1267\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0898 - accuracy: 0.1566 - val_loss: 0.0898 - val_accuracy: 0.1022\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0897 - accuracy: 0.1136 - val_loss: 0.0898 - val_accuracy: 0.2667\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0896 - accuracy: 0.2539 - val_loss: 0.0897 - val_accuracy: 0.1800\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0896 - accuracy: 0.1166 - val_loss: 0.0896 - val_accuracy: 0.1533\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0895 - accuracy: 0.3007 - val_loss: 0.0895 - val_accuracy: 0.4133\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0894 - accuracy: 0.3578 - val_loss: 0.0895 - val_accuracy: 0.3756\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0893 - accuracy: 0.2687 - val_loss: 0.0894 - val_accuracy: 0.3756\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0893 - accuracy: 0.3081 - val_loss: 0.0894 - val_accuracy: 0.3178\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0892 - accuracy: 0.3482 - val_loss: 0.0892 - val_accuracy: 0.2733\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0891 - accuracy: 0.4529 - val_loss: 0.0891 - val_accuracy: 0.3200\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0890 - accuracy: 0.2197 - val_loss: 0.0890 - val_accuracy: 0.3444\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0889 - accuracy: 0.3875 - val_loss: 0.0890 - val_accuracy: 0.4622\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0888 - accuracy: 0.3764 - val_loss: 0.0889 - val_accuracy: 0.3511\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0887 - accuracy: 0.5130 - val_loss: 0.0888 - val_accuracy: 0.5844\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0886 - accuracy: 0.5679 - val_loss: 0.0887 - val_accuracy: 0.5067\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0885 - accuracy: 0.4699 - val_loss: 0.0886 - val_accuracy: 0.3378\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0884 - accuracy: 0.3504 - val_loss: 0.0885 - val_accuracy: 0.3733\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0883 - accuracy: 0.5464 - val_loss: 0.0884 - val_accuracy: 0.5600\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0882 - accuracy: 0.4811 - val_loss: 0.0883 - val_accuracy: 0.5578\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0881 - accuracy: 0.5872 - val_loss: 0.0882 - val_accuracy: 0.5378\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0880 - accuracy: 0.5672 - val_loss: 0.0881 - val_accuracy: 0.4222\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0879 - accuracy: 0.4484 - val_loss: 0.0880 - val_accuracy: 0.4978\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0878 - accuracy: 0.5464 - val_loss: 0.0879 - val_accuracy: 0.4844\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0876 - accuracy: 0.4729 - val_loss: 0.0878 - val_accuracy: 0.5267\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0875 - accuracy: 0.4959 - val_loss: 0.0876 - val_accuracy: 0.4600\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0874 - accuracy: 0.5568 - val_loss: 0.0874 - val_accuracy: 0.5844\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0872 - accuracy: 0.6184 - val_loss: 0.0874 - val_accuracy: 0.5911\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0871 - accuracy: 0.5739 - val_loss: 0.0872 - val_accuracy: 0.5267\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0869 - accuracy: 0.5226 - val_loss: 0.0871 - val_accuracy: 0.4311\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0868 - accuracy: 0.4796 - val_loss: 0.0869 - val_accuracy: 0.5756\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0866 - accuracy: 0.5694 - val_loss: 0.0867 - val_accuracy: 0.5089\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0864 - accuracy: 0.5575 - val_loss: 0.0866 - val_accuracy: 0.5644\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0863 - accuracy: 0.4469 - val_loss: 0.0865 - val_accuracy: 0.4711\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0861 - accuracy: 0.5115 - val_loss: 0.0863 - val_accuracy: 0.5178\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0859 - accuracy: 0.5256 - val_loss: 0.0861 - val_accuracy: 0.6000\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0857 - accuracy: 0.6169 - val_loss: 0.0859 - val_accuracy: 0.5644\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0855 - accuracy: 0.5627 - val_loss: 0.0858 - val_accuracy: 0.5733\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0853 - accuracy: 0.6125 - val_loss: 0.0855 - val_accuracy: 0.6178\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0851 - accuracy: 0.6696 - val_loss: 0.0853 - val_accuracy: 0.6356\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0849 - accuracy: 0.6192 - val_loss: 0.0851 - val_accuracy: 0.4978\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0847 - accuracy: 0.4863 - val_loss: 0.0849 - val_accuracy: 0.5600\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0844 - accuracy: 0.5813 - val_loss: 0.0847 - val_accuracy: 0.5556\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0841 - accuracy: 0.6095 - val_loss: 0.0843 - val_accuracy: 0.6067\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0838 - accuracy: 0.6050 - val_loss: 0.0841 - val_accuracy: 0.5533\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0836 - accuracy: 0.5108 - val_loss: 0.0839 - val_accuracy: 0.4867\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0833 - accuracy: 0.5122 - val_loss: 0.0836 - val_accuracy: 0.5067\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0830 - accuracy: 0.6281 - val_loss: 0.0833 - val_accuracy: 0.6778\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0827 - accuracy: 0.6592 - val_loss: 0.0830 - val_accuracy: 0.6000\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0823 - accuracy: 0.5546 - val_loss: 0.0827 - val_accuracy: 0.5333\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0820 - accuracy: 0.5857 - val_loss: 0.0823 - val_accuracy: 0.6089\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0817 - accuracy: 0.6117 - val_loss: 0.0819 - val_accuracy: 0.5889\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0813 - accuracy: 0.5509 - val_loss: 0.0818 - val_accuracy: 0.4756\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0809 - accuracy: 0.5382 - val_loss: 0.0812 - val_accuracy: 0.5800\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0804 - accuracy: 0.5791 - val_loss: 0.0808 - val_accuracy: 0.5822\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0800 - accuracy: 0.5642 - val_loss: 0.0805 - val_accuracy: 0.5511\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0795 - accuracy: 0.6147 - val_loss: 0.0799 - val_accuracy: 0.6378\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0791 - accuracy: 0.6147 - val_loss: 0.0796 - val_accuracy: 0.5867\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0786 - accuracy: 0.5991 - val_loss: 0.0791 - val_accuracy: 0.5933\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0781 - accuracy: 0.5991 - val_loss: 0.0786 - val_accuracy: 0.6111\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0776 - accuracy: 0.6006 - val_loss: 0.0781 - val_accuracy: 0.6000\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0770 - accuracy: 0.6281 - val_loss: 0.0776 - val_accuracy: 0.6289\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0765 - accuracy: 0.6273 - val_loss: 0.0771 - val_accuracy: 0.6133\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0759 - accuracy: 0.6177 - val_loss: 0.0766 - val_accuracy: 0.6244\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0754 - accuracy: 0.6503 - val_loss: 0.0759 - val_accuracy: 0.6489\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0747 - accuracy: 0.6258 - val_loss: 0.0754 - val_accuracy: 0.6000\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0741 - accuracy: 0.6169 - val_loss: 0.0747 - val_accuracy: 0.6067\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0735 - accuracy: 0.6362 - val_loss: 0.0742 - val_accuracy: 0.6289\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0728 - accuracy: 0.6622 - val_loss: 0.0735 - val_accuracy: 0.6422\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0722 - accuracy: 0.6466 - val_loss: 0.0729 - val_accuracy: 0.6378\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0714 - accuracy: 0.6578 - val_loss: 0.0722 - val_accuracy: 0.6400\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0708 - accuracy: 0.6496 - val_loss: 0.0715 - val_accuracy: 0.6533\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0701 - accuracy: 0.6637 - val_loss: 0.0707 - val_accuracy: 0.6778\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0694 - accuracy: 0.6682 - val_loss: 0.0702 - val_accuracy: 0.6422\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0686 - accuracy: 0.6548 - val_loss: 0.0694 - val_accuracy: 0.6511\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0679 - accuracy: 0.6726 - val_loss: 0.0686 - val_accuracy: 0.6689\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0671 - accuracy: 0.6808 - val_loss: 0.0679 - val_accuracy: 0.6689\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0664 - accuracy: 0.6756 - val_loss: 0.0672 - val_accuracy: 0.6578\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0656 - accuracy: 0.6927 - val_loss: 0.0664 - val_accuracy: 0.6933\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0649 - accuracy: 0.7001 - val_loss: 0.0657 - val_accuracy: 0.6800\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0641 - accuracy: 0.7082 - val_loss: 0.0649 - val_accuracy: 0.6956\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0633 - accuracy: 0.7120 - val_loss: 0.0643 - val_accuracy: 0.6822\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0626 - accuracy: 0.7120 - val_loss: 0.0634 - val_accuracy: 0.6956\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0618 - accuracy: 0.7157 - val_loss: 0.0627 - val_accuracy: 0.7000\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.7231 - val_loss: 0.0620 - val_accuracy: 0.7000\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0602 - accuracy: 0.7164 - val_loss: 0.0612 - val_accuracy: 0.7022\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0595 - accuracy: 0.7231 - val_loss: 0.0605 - val_accuracy: 0.7000\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0588 - accuracy: 0.7246 - val_loss: 0.0597 - val_accuracy: 0.7044\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0581 - accuracy: 0.7298 - val_loss: 0.0589 - val_accuracy: 0.7200\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0573 - accuracy: 0.7335 - val_loss: 0.0584 - val_accuracy: 0.7089\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0566 - accuracy: 0.7342 - val_loss: 0.0576 - val_accuracy: 0.7067\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0558 - accuracy: 0.7387 - val_loss: 0.0567 - val_accuracy: 0.7378\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0551 - accuracy: 0.7624 - val_loss: 0.0561 - val_accuracy: 0.7267\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0544 - accuracy: 0.7350 - val_loss: 0.0556 - val_accuracy: 0.7044\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0536 - accuracy: 0.7454 - val_loss: 0.0548 - val_accuracy: 0.7533\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0530 - accuracy: 0.7773 - val_loss: 0.0540 - val_accuracy: 0.7578\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0523 - accuracy: 0.7647 - val_loss: 0.0534 - val_accuracy: 0.7267\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0517 - accuracy: 0.7528 - val_loss: 0.0528 - val_accuracy: 0.7289\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0509 - accuracy: 0.7691 - val_loss: 0.0520 - val_accuracy: 0.7533\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0503 - accuracy: 0.7736 - val_loss: 0.0514 - val_accuracy: 0.7644\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0496 - accuracy: 0.7862 - val_loss: 0.0508 - val_accuracy: 0.7644\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0490 - accuracy: 0.7654 - val_loss: 0.0502 - val_accuracy: 0.7356\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0483 - accuracy: 0.7736 - val_loss: 0.0494 - val_accuracy: 0.7800\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 0.0478 - accuracy: 0.7996 - val_loss: 0.0490 - val_accuracy: 0.7933\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 14ms/step - loss: 0.0471 - accuracy: 0.7996 - val_loss: 0.0484 - val_accuracy: 0.7644\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0465 - accuracy: 0.7721 - val_loss: 0.0477 - val_accuracy: 0.7578\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0459 - accuracy: 0.7847 - val_loss: 0.0471 - val_accuracy: 0.7911\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0453 - accuracy: 0.7944 - val_loss: 0.0466 - val_accuracy: 0.7822\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0447 - accuracy: 0.7981 - val_loss: 0.0461 - val_accuracy: 0.7956\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0442 - accuracy: 0.8114 - val_loss: 0.0455 - val_accuracy: 0.8000\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0436 - accuracy: 0.8085 - val_loss: 0.0450 - val_accuracy: 0.7978\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0431 - accuracy: 0.8003 - val_loss: 0.0444 - val_accuracy: 0.7933\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0425 - accuracy: 0.8010 - val_loss: 0.0439 - val_accuracy: 0.7978\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0420 - accuracy: 0.8025 - val_loss: 0.0434 - val_accuracy: 0.7956\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0415 - accuracy: 0.8085 - val_loss: 0.0428 - val_accuracy: 0.8044\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0410 - accuracy: 0.8077 - val_loss: 0.0424 - val_accuracy: 0.7956\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0405 - accuracy: 0.8166 - val_loss: 0.0420 - val_accuracy: 0.8133\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0400 - accuracy: 0.8218 - val_loss: 0.0415 - val_accuracy: 0.8044\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0396 - accuracy: 0.8129 - val_loss: 0.0409 - val_accuracy: 0.8089\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0391 - accuracy: 0.8203 - val_loss: 0.0405 - val_accuracy: 0.8067\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0387 - accuracy: 0.8241 - val_loss: 0.0401 - val_accuracy: 0.8111\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0382 - accuracy: 0.8174 - val_loss: 0.0396 - val_accuracy: 0.8067\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0377 - accuracy: 0.8203 - val_loss: 0.0393 - val_accuracy: 0.8156\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0373 - accuracy: 0.8255 - val_loss: 0.0388 - val_accuracy: 0.8111\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0369 - accuracy: 0.8248 - val_loss: 0.0384 - val_accuracy: 0.8067\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0365 - accuracy: 0.8293 - val_loss: 0.0381 - val_accuracy: 0.8111\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 0.8293 - val_loss: 0.0376 - val_accuracy: 0.8156\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0357 - accuracy: 0.8189 - val_loss: 0.0373 - val_accuracy: 0.8133\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0353 - accuracy: 0.8278 - val_loss: 0.0368 - val_accuracy: 0.8089\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0349 - accuracy: 0.8322 - val_loss: 0.0365 - val_accuracy: 0.8133\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0346 - accuracy: 0.8263 - val_loss: 0.0362 - val_accuracy: 0.8156\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0342 - accuracy: 0.8285 - val_loss: 0.0357 - val_accuracy: 0.8089\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0338 - accuracy: 0.8293 - val_loss: 0.0355 - val_accuracy: 0.8156\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0335 - accuracy: 0.8300 - val_loss: 0.0351 - val_accuracy: 0.8222\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0332 - accuracy: 0.8344 - val_loss: 0.0347 - val_accuracy: 0.8200\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0329 - accuracy: 0.8374 - val_loss: 0.0344 - val_accuracy: 0.8289\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0325 - accuracy: 0.8374 - val_loss: 0.0341 - val_accuracy: 0.8178\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0321 - accuracy: 0.8448 - val_loss: 0.0339 - val_accuracy: 0.8267\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0318 - accuracy: 0.8382 - val_loss: 0.0336 - val_accuracy: 0.8178\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0315 - accuracy: 0.8404 - val_loss: 0.0331 - val_accuracy: 0.8222\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0312 - accuracy: 0.8545 - val_loss: 0.0329 - val_accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0309 - accuracy: 0.8463 - val_loss: 0.0326 - val_accuracy: 0.8222\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0306 - accuracy: 0.8523 - val_loss: 0.0323 - val_accuracy: 0.8311\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0303 - accuracy: 0.8582 - val_loss: 0.0321 - val_accuracy: 0.8378\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0300 - accuracy: 0.8500 - val_loss: 0.0317 - val_accuracy: 0.8267\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0298 - accuracy: 0.8589 - val_loss: 0.0314 - val_accuracy: 0.8356\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0294 - accuracy: 0.8530 - val_loss: 0.0313 - val_accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0292 - accuracy: 0.8641 - val_loss: 0.0309 - val_accuracy: 0.8467\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0289 - accuracy: 0.8679 - val_loss: 0.0307 - val_accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0286 - accuracy: 0.8664 - val_loss: 0.0305 - val_accuracy: 0.8356\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0284 - accuracy: 0.8679 - val_loss: 0.0301 - val_accuracy: 0.8489\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0281 - accuracy: 0.8790 - val_loss: 0.0299 - val_accuracy: 0.8467\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0278 - accuracy: 0.8723 - val_loss: 0.0297 - val_accuracy: 0.8511\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0276 - accuracy: 0.8760 - val_loss: 0.0295 - val_accuracy: 0.8489\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 0.8790 - val_loss: 0.0292 - val_accuracy: 0.8533\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0271 - accuracy: 0.8842 - val_loss: 0.0290 - val_accuracy: 0.8556\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0269 - accuracy: 0.8842 - val_loss: 0.0287 - val_accuracy: 0.8533\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 0.8864 - val_loss: 0.0285 - val_accuracy: 0.8622\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0264 - accuracy: 0.8931 - val_loss: 0.0283 - val_accuracy: 0.8578\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0262 - accuracy: 0.8857 - val_loss: 0.0281 - val_accuracy: 0.8556\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.8931 - val_loss: 0.0279 - val_accuracy: 0.8667\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0257 - accuracy: 0.8924 - val_loss: 0.0277 - val_accuracy: 0.8556\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0255 - accuracy: 0.8968 - val_loss: 0.0274 - val_accuracy: 0.8622\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0253 - accuracy: 0.8968 - val_loss: 0.0273 - val_accuracy: 0.8667\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.8998 - val_loss: 0.0270 - val_accuracy: 0.8667\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0249 - accuracy: 0.8924 - val_loss: 0.0269 - val_accuracy: 0.8600\n",
      "Epoch 169/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.8916 - val_loss: 0.0266 - val_accuracy: 0.8667\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9057 - val_loss: 0.0264 - val_accuracy: 0.8756\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.8998 - val_loss: 0.0263 - val_accuracy: 0.8644\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0241 - accuracy: 0.8901 - val_loss: 0.0261 - val_accuracy: 0.8622\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0240 - accuracy: 0.9005 - val_loss: 0.0259 - val_accuracy: 0.8733\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0237 - accuracy: 0.9057 - val_loss: 0.0257 - val_accuracy: 0.8622\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0235 - accuracy: 0.8990 - val_loss: 0.0255 - val_accuracy: 0.8689\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0233 - accuracy: 0.9020 - val_loss: 0.0254 - val_accuracy: 0.8756\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 0.0232 - accuracy: 0.9087 - val_loss: 0.0251 - val_accuracy: 0.8800\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9072 - val_loss: 0.0249 - val_accuracy: 0.8778\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9079 - val_loss: 0.0248 - val_accuracy: 0.8778\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0226 - accuracy: 0.9065 - val_loss: 0.0247 - val_accuracy: 0.8756\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0224 - accuracy: 0.9042 - val_loss: 0.0245 - val_accuracy: 0.8822\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0223 - accuracy: 0.9117 - val_loss: 0.0243 - val_accuracy: 0.8844\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0221 - accuracy: 0.9072 - val_loss: 0.0242 - val_accuracy: 0.8756\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0219 - accuracy: 0.9072 - val_loss: 0.0240 - val_accuracy: 0.8844\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0218 - accuracy: 0.9169 - val_loss: 0.0238 - val_accuracy: 0.8889\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0216 - accuracy: 0.9102 - val_loss: 0.0238 - val_accuracy: 0.8778\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9109 - val_loss: 0.0235 - val_accuracy: 0.8822\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0212 - accuracy: 0.9139 - val_loss: 0.0233 - val_accuracy: 0.8889\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 0.9154 - val_loss: 0.0232 - val_accuracy: 0.8844\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0209 - accuracy: 0.9154 - val_loss: 0.0231 - val_accuracy: 0.8844\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0208 - accuracy: 0.9146 - val_loss: 0.0229 - val_accuracy: 0.8889\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0206 - accuracy: 0.9169 - val_loss: 0.0229 - val_accuracy: 0.8844\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0205 - accuracy: 0.9146 - val_loss: 0.0226 - val_accuracy: 0.8844\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0203 - accuracy: 0.9161 - val_loss: 0.0225 - val_accuracy: 0.8844\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0202 - accuracy: 0.9191 - val_loss: 0.0224 - val_accuracy: 0.8956\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0200 - accuracy: 0.9183 - val_loss: 0.0222 - val_accuracy: 0.8933\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0199 - accuracy: 0.9183 - val_loss: 0.0221 - val_accuracy: 0.8867\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0198 - accuracy: 0.9206 - val_loss: 0.0219 - val_accuracy: 0.8933\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0196 - accuracy: 0.9183 - val_loss: 0.0218 - val_accuracy: 0.8867\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0195 - accuracy: 0.9206 - val_loss: 0.0216 - val_accuracy: 0.8933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28f60f280>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128,\n",
    "          epochs=200, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, ready to do that again?  The basic loading, splitting, and normalization of the data are done for you below.  Try to adapt the pipeline you just saw to the wine data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(wine.data, wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95886716, 0.29310345, 0.71428571, 0.54333333, 0.72839506,\n",
       "       0.90909091, 0.76335878, 0.39393939, 0.56703911, 0.49076923,\n",
       "       0.5497076 , 0.8275    , 0.57738095])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples, num_features = X_train.shape\n",
    "for j in range(num_features):\n",
    "  X_train[:,j] /= X_train[:,j].max()\n",
    "  X_valid[:,j] /= X_valid[:,j].max()\n",
    "\n",
    "X_train[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO to_categorical\n",
    "n_classes = len(set(y_train))  # Determine the number of unique classes\n",
    "y_train = tf.keras.utils.to_categorical(y_train, n_classes)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO create model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='sigmoid', input_shape=(13,)))  # Wine dataset has 13 features\n",
    "model.add(Dense(n_classes, activation='softmax'))  # Output layer for n_classes categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO compile model\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 377ms/step - loss: 0.2240 - accuracy: 0.3910 - val_loss: 0.2206 - val_accuracy: 0.4222\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2216 - accuracy: 0.3910 - val_loss: 0.2199 - val_accuracy: 0.4222\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2212 - accuracy: 0.3910 - val_loss: 0.2193 - val_accuracy: 0.4222\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2209 - accuracy: 0.3910 - val_loss: 0.2189 - val_accuracy: 0.4222\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2202 - accuracy: 0.3910 - val_loss: 0.2187 - val_accuracy: 0.4222\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2194 - accuracy: 0.3910 - val_loss: 0.2187 - val_accuracy: 0.4222\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2188 - accuracy: 0.3910 - val_loss: 0.2185 - val_accuracy: 0.4222\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2187 - accuracy: 0.3910 - val_loss: 0.2183 - val_accuracy: 0.4222\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2186 - accuracy: 0.3910 - val_loss: 0.2182 - val_accuracy: 0.4222\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2181 - accuracy: 0.3910 - val_loss: 0.2184 - val_accuracy: 0.4222\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2177 - accuracy: 0.3910 - val_loss: 0.2187 - val_accuracy: 0.4222\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2171 - accuracy: 0.3910 - val_loss: 0.2187 - val_accuracy: 0.4222\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2164 - accuracy: 0.3910 - val_loss: 0.2192 - val_accuracy: 0.4222\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2157 - accuracy: 0.3910 - val_loss: 0.2205 - val_accuracy: 0.5111\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2155 - accuracy: 0.4887 - val_loss: 0.2221 - val_accuracy: 0.2667\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2157 - accuracy: 0.3534 - val_loss: 0.2241 - val_accuracy: 0.2667\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2162 - accuracy: 0.3534 - val_loss: 0.2266 - val_accuracy: 0.2667\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2173 - accuracy: 0.3534 - val_loss: 0.2276 - val_accuracy: 0.2667\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2176 - accuracy: 0.3534 - val_loss: 0.2261 - val_accuracy: 0.2667\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2168 - accuracy: 0.3534 - val_loss: 0.2235 - val_accuracy: 0.2667\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2157 - accuracy: 0.3534 - val_loss: 0.2206 - val_accuracy: 0.2667\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2145 - accuracy: 0.3534 - val_loss: 0.2180 - val_accuracy: 0.2667\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2134 - accuracy: 0.3534 - val_loss: 0.2165 - val_accuracy: 0.2667\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2124 - accuracy: 0.3534 - val_loss: 0.2154 - val_accuracy: 0.2667\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2117 - accuracy: 0.3534 - val_loss: 0.2144 - val_accuracy: 0.2667\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2110 - accuracy: 0.3684 - val_loss: 0.2139 - val_accuracy: 0.3556\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2105 - accuracy: 0.5414 - val_loss: 0.2131 - val_accuracy: 0.6667\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2102 - accuracy: 0.6316 - val_loss: 0.2125 - val_accuracy: 0.6000\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2098 - accuracy: 0.4812 - val_loss: 0.2123 - val_accuracy: 0.6000\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2095 - accuracy: 0.4436 - val_loss: 0.2124 - val_accuracy: 0.6000\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2095 - accuracy: 0.4361 - val_loss: 0.2129 - val_accuracy: 0.6889\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2093 - accuracy: 0.6015 - val_loss: 0.2135 - val_accuracy: 0.5111\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2090 - accuracy: 0.6617 - val_loss: 0.2139 - val_accuracy: 0.2667\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2089 - accuracy: 0.3684 - val_loss: 0.2137 - val_accuracy: 0.2667\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2084 - accuracy: 0.3534 - val_loss: 0.2128 - val_accuracy: 0.2667\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2079 - accuracy: 0.3534 - val_loss: 0.2119 - val_accuracy: 0.2667\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2073 - accuracy: 0.3534 - val_loss: 0.2109 - val_accuracy: 0.2667\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2068 - accuracy: 0.3534 - val_loss: 0.2101 - val_accuracy: 0.2667\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.2065 - accuracy: 0.3534 - val_loss: 0.2098 - val_accuracy: 0.2667\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.2065 - accuracy: 0.3534 - val_loss: 0.2096 - val_accuracy: 0.2889\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2068 - accuracy: 0.3609 - val_loss: 0.2091 - val_accuracy: 0.4667\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2070 - accuracy: 0.4361 - val_loss: 0.2087 - val_accuracy: 0.5111\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2067 - accuracy: 0.5263 - val_loss: 0.2084 - val_accuracy: 0.4889\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2063 - accuracy: 0.4962 - val_loss: 0.2077 - val_accuracy: 0.5556\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2059 - accuracy: 0.5263 - val_loss: 0.2071 - val_accuracy: 0.4889\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2051 - accuracy: 0.4962 - val_loss: 0.2070 - val_accuracy: 0.3778\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2044 - accuracy: 0.4135 - val_loss: 0.2070 - val_accuracy: 0.2889\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2038 - accuracy: 0.3534 - val_loss: 0.2068 - val_accuracy: 0.2667\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2031 - accuracy: 0.3534 - val_loss: 0.2060 - val_accuracy: 0.2667\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2024 - accuracy: 0.3534 - val_loss: 0.2060 - val_accuracy: 0.2667\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2020 - accuracy: 0.3534 - val_loss: 0.2067 - val_accuracy: 0.2667\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2020 - accuracy: 0.3534 - val_loss: 0.2073 - val_accuracy: 0.2667\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2020 - accuracy: 0.3534 - val_loss: 0.2077 - val_accuracy: 0.2667\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2020 - accuracy: 0.3534 - val_loss: 0.2075 - val_accuracy: 0.2667\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2017 - accuracy: 0.3534 - val_loss: 0.2061 - val_accuracy: 0.2667\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2010 - accuracy: 0.3534 - val_loss: 0.2059 - val_accuracy: 0.2667\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.2007 - accuracy: 0.3534 - val_loss: 0.2067 - val_accuracy: 0.2667\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2009 - accuracy: 0.3534 - val_loss: 0.2061 - val_accuracy: 0.2667\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.2005 - accuracy: 0.3534 - val_loss: 0.2042 - val_accuracy: 0.2889\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1996 - accuracy: 0.4662 - val_loss: 0.2022 - val_accuracy: 0.4444\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1987 - accuracy: 0.6090 - val_loss: 0.2010 - val_accuracy: 0.5333\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1980 - accuracy: 0.6617 - val_loss: 0.1997 - val_accuracy: 0.5556\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1973 - accuracy: 0.6692 - val_loss: 0.1981 - val_accuracy: 0.6000\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1965 - accuracy: 0.6917 - val_loss: 0.1966 - val_accuracy: 0.6000\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1958 - accuracy: 0.6917 - val_loss: 0.1953 - val_accuracy: 0.6444\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1952 - accuracy: 0.6917 - val_loss: 0.1948 - val_accuracy: 0.6000\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1945 - accuracy: 0.6992 - val_loss: 0.1951 - val_accuracy: 0.5556\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1941 - accuracy: 0.6541 - val_loss: 0.1966 - val_accuracy: 0.3333\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1943 - accuracy: 0.3835 - val_loss: 0.1988 - val_accuracy: 0.3111\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1954 - accuracy: 0.3684 - val_loss: 0.2001 - val_accuracy: 0.3111\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1960 - accuracy: 0.4060 - val_loss: 0.2002 - val_accuracy: 0.4000\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1963 - accuracy: 0.4211 - val_loss: 0.1996 - val_accuracy: 0.4889\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1961 - accuracy: 0.4737 - val_loss: 0.1986 - val_accuracy: 0.5778\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1957 - accuracy: 0.5263 - val_loss: 0.1969 - val_accuracy: 0.5778\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1952 - accuracy: 0.5714 - val_loss: 0.1947 - val_accuracy: 0.5778\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1941 - accuracy: 0.5940 - val_loss: 0.1927 - val_accuracy: 0.5778\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1927 - accuracy: 0.5940 - val_loss: 0.1909 - val_accuracy: 0.5778\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1914 - accuracy: 0.6015 - val_loss: 0.1888 - val_accuracy: 0.5778\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1903 - accuracy: 0.6767 - val_loss: 0.1867 - val_accuracy: 0.7778\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1892 - accuracy: 0.8421 - val_loss: 0.1846 - val_accuracy: 0.9111\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1882 - accuracy: 0.9248 - val_loss: 0.1828 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1875 - accuracy: 0.8647 - val_loss: 0.1816 - val_accuracy: 0.7778\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1880 - accuracy: 0.5789 - val_loss: 0.1811 - val_accuracy: 0.5778\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1892 - accuracy: 0.4211 - val_loss: 0.1809 - val_accuracy: 0.4889\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1898 - accuracy: 0.3985 - val_loss: 0.1806 - val_accuracy: 0.4889\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1896 - accuracy: 0.3985 - val_loss: 0.1803 - val_accuracy: 0.4889\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1888 - accuracy: 0.3985 - val_loss: 0.1803 - val_accuracy: 0.5778\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1875 - accuracy: 0.4135 - val_loss: 0.1806 - val_accuracy: 0.6667\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1862 - accuracy: 0.5038 - val_loss: 0.1807 - val_accuracy: 0.7778\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1852 - accuracy: 0.6241 - val_loss: 0.1803 - val_accuracy: 0.8222\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1846 - accuracy: 0.7068 - val_loss: 0.1796 - val_accuracy: 0.8222\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1841 - accuracy: 0.6992 - val_loss: 0.1791 - val_accuracy: 0.8667\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1836 - accuracy: 0.7594 - val_loss: 0.1785 - val_accuracy: 0.9111\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1830 - accuracy: 0.8120 - val_loss: 0.1777 - val_accuracy: 0.9778\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1824 - accuracy: 0.8496 - val_loss: 0.1766 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1820 - accuracy: 0.8647 - val_loss: 0.1756 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1817 - accuracy: 0.8722 - val_loss: 0.1750 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1812 - accuracy: 0.8722 - val_loss: 0.1747 - val_accuracy: 0.9778\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1806 - accuracy: 0.8947 - val_loss: 0.1748 - val_accuracy: 0.9556\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1802 - accuracy: 0.9323 - val_loss: 0.1754 - val_accuracy: 0.8889\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1799 - accuracy: 0.9248 - val_loss: 0.1759 - val_accuracy: 0.8444\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1797 - accuracy: 0.8797 - val_loss: 0.1756 - val_accuracy: 0.8444\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1792 - accuracy: 0.8872 - val_loss: 0.1748 - val_accuracy: 0.8444\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1787 - accuracy: 0.8947 - val_loss: 0.1736 - val_accuracy: 0.8667\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1782 - accuracy: 0.9098 - val_loss: 0.1723 - val_accuracy: 0.8889\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1778 - accuracy: 0.9323 - val_loss: 0.1714 - val_accuracy: 0.8889\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1774 - accuracy: 0.9398 - val_loss: 0.1712 - val_accuracy: 0.8889\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1770 - accuracy: 0.9323 - val_loss: 0.1710 - val_accuracy: 0.8889\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.1765 - accuracy: 0.9248 - val_loss: 0.1706 - val_accuracy: 0.8889\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1761 - accuracy: 0.9248 - val_loss: 0.1700 - val_accuracy: 0.8889\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1756 - accuracy: 0.9173 - val_loss: 0.1697 - val_accuracy: 0.8889\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1752 - accuracy: 0.9098 - val_loss: 0.1698 - val_accuracy: 0.8444\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1748 - accuracy: 0.8872 - val_loss: 0.1703 - val_accuracy: 0.7778\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1747 - accuracy: 0.8647 - val_loss: 0.1709 - val_accuracy: 0.7333\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1747 - accuracy: 0.7970 - val_loss: 0.1700 - val_accuracy: 0.7333\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1742 - accuracy: 0.7970 - val_loss: 0.1688 - val_accuracy: 0.7778\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1735 - accuracy: 0.8421 - val_loss: 0.1685 - val_accuracy: 0.7778\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1729 - accuracy: 0.8421 - val_loss: 0.1692 - val_accuracy: 0.7333\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1726 - accuracy: 0.8045 - val_loss: 0.1704 - val_accuracy: 0.6444\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1728 - accuracy: 0.7519 - val_loss: 0.1715 - val_accuracy: 0.6222\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1729 - accuracy: 0.6917 - val_loss: 0.1726 - val_accuracy: 0.5778\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1731 - accuracy: 0.6090 - val_loss: 0.1748 - val_accuracy: 0.5778\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1740 - accuracy: 0.5639 - val_loss: 0.1787 - val_accuracy: 0.5556\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1761 - accuracy: 0.5188 - val_loss: 0.1819 - val_accuracy: 0.5111\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1780 - accuracy: 0.4962 - val_loss: 0.1822 - val_accuracy: 0.4889\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1779 - accuracy: 0.4737 - val_loss: 0.1803 - val_accuracy: 0.4889\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1767 - accuracy: 0.4737 - val_loss: 0.1783 - val_accuracy: 0.5111\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1752 - accuracy: 0.5038 - val_loss: 0.1750 - val_accuracy: 0.5333\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1732 - accuracy: 0.5263 - val_loss: 0.1707 - val_accuracy: 0.6444\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1707 - accuracy: 0.6842 - val_loss: 0.1666 - val_accuracy: 0.8444\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1689 - accuracy: 0.7970 - val_loss: 0.1636 - val_accuracy: 0.8667\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1683 - accuracy: 0.8271 - val_loss: 0.1616 - val_accuracy: 0.8667\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1686 - accuracy: 0.7594 - val_loss: 0.1600 - val_accuracy: 0.8000\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1691 - accuracy: 0.6466 - val_loss: 0.1590 - val_accuracy: 0.7556\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1704 - accuracy: 0.5338 - val_loss: 0.1580 - val_accuracy: 0.7111\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1705 - accuracy: 0.5113 - val_loss: 0.1569 - val_accuracy: 0.7333\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1699 - accuracy: 0.5188 - val_loss: 0.1556 - val_accuracy: 0.7333\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1688 - accuracy: 0.5714 - val_loss: 0.1539 - val_accuracy: 0.8667\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1668 - accuracy: 0.6541 - val_loss: 0.1528 - val_accuracy: 0.9556\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1647 - accuracy: 0.7820 - val_loss: 0.1525 - val_accuracy: 0.9778\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1632 - accuracy: 0.8947 - val_loss: 0.1527 - val_accuracy: 0.9778\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1623 - accuracy: 0.9398 - val_loss: 0.1532 - val_accuracy: 0.9111\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1619 - accuracy: 0.9398 - val_loss: 0.1534 - val_accuracy: 0.8667\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1616 - accuracy: 0.9248 - val_loss: 0.1534 - val_accuracy: 0.8667\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1615 - accuracy: 0.9023 - val_loss: 0.1531 - val_accuracy: 0.8667\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1612 - accuracy: 0.9023 - val_loss: 0.1521 - val_accuracy: 0.8667\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1608 - accuracy: 0.9098 - val_loss: 0.1504 - val_accuracy: 0.8889\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1602 - accuracy: 0.9248 - val_loss: 0.1488 - val_accuracy: 0.9556\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1596 - accuracy: 0.9248 - val_loss: 0.1478 - val_accuracy: 0.9778\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1591 - accuracy: 0.9248 - val_loss: 0.1473 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1588 - accuracy: 0.9248 - val_loss: 0.1472 - val_accuracy: 0.9778\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1590 - accuracy: 0.8872 - val_loss: 0.1472 - val_accuracy: 0.9556\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1590 - accuracy: 0.8571 - val_loss: 0.1476 - val_accuracy: 0.9778\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1589 - accuracy: 0.8496 - val_loss: 0.1479 - val_accuracy: 0.9778\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1587 - accuracy: 0.8722 - val_loss: 0.1478 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1582 - accuracy: 0.8647 - val_loss: 0.1477 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1578 - accuracy: 0.8647 - val_loss: 0.1478 - val_accuracy: 0.9778\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1576 - accuracy: 0.8647 - val_loss: 0.1477 - val_accuracy: 0.9778\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.1572 - accuracy: 0.8571 - val_loss: 0.1467 - val_accuracy: 0.9778\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1561 - accuracy: 0.8722 - val_loss: 0.1452 - val_accuracy: 0.9778\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1549 - accuracy: 0.8947 - val_loss: 0.1440 - val_accuracy: 0.9778\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1538 - accuracy: 0.9248 - val_loss: 0.1431 - val_accuracy: 0.9556\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1531 - accuracy: 0.9323 - val_loss: 0.1427 - val_accuracy: 0.9111\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1527 - accuracy: 0.9323 - val_loss: 0.1430 - val_accuracy: 0.8667\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1525 - accuracy: 0.9248 - val_loss: 0.1433 - val_accuracy: 0.8667\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1522 - accuracy: 0.9023 - val_loss: 0.1442 - val_accuracy: 0.8222\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1523 - accuracy: 0.8722 - val_loss: 0.1449 - val_accuracy: 0.8222\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1522 - accuracy: 0.8571 - val_loss: 0.1451 - val_accuracy: 0.7778\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1525 - accuracy: 0.8271 - val_loss: 0.1450 - val_accuracy: 0.7556\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1525 - accuracy: 0.8120 - val_loss: 0.1444 - val_accuracy: 0.7333\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1522 - accuracy: 0.8120 - val_loss: 0.1434 - val_accuracy: 0.7778\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1520 - accuracy: 0.8195 - val_loss: 0.1420 - val_accuracy: 0.8000\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1517 - accuracy: 0.8346 - val_loss: 0.1404 - val_accuracy: 0.8222\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1510 - accuracy: 0.8722 - val_loss: 0.1387 - val_accuracy: 0.8667\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1501 - accuracy: 0.8872 - val_loss: 0.1369 - val_accuracy: 0.9333\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1496 - accuracy: 0.8947 - val_loss: 0.1357 - val_accuracy: 0.9333\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1489 - accuracy: 0.8947 - val_loss: 0.1352 - val_accuracy: 0.9333\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1483 - accuracy: 0.8947 - val_loss: 0.1348 - val_accuracy: 0.9333\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1474 - accuracy: 0.9098 - val_loss: 0.1350 - val_accuracy: 0.8889\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.1464 - accuracy: 0.9173 - val_loss: 0.1363 - val_accuracy: 0.8667\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.1460 - accuracy: 0.8797 - val_loss: 0.1379 - val_accuracy: 0.8222\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1460 - accuracy: 0.8647 - val_loss: 0.1386 - val_accuracy: 0.8222\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1458 - accuracy: 0.8571 - val_loss: 0.1387 - val_accuracy: 0.8444\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1455 - accuracy: 0.8647 - val_loss: 0.1388 - val_accuracy: 0.8444\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1454 - accuracy: 0.8571 - val_loss: 0.1385 - val_accuracy: 0.8444\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1450 - accuracy: 0.8722 - val_loss: 0.1375 - val_accuracy: 0.8667\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.1446 - accuracy: 0.8947 - val_loss: 0.1363 - val_accuracy: 0.9111\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1440 - accuracy: 0.9248 - val_loss: 0.1345 - val_accuracy: 0.9111\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1433 - accuracy: 0.9248 - val_loss: 0.1320 - val_accuracy: 0.9778\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 0.1424 - accuracy: 0.9398 - val_loss: 0.1297 - val_accuracy: 0.9778\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1417 - accuracy: 0.9398 - val_loss: 0.1276 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1420 - accuracy: 0.9098 - val_loss: 0.1264 - val_accuracy: 0.9556\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1434 - accuracy: 0.8271 - val_loss: 0.1255 - val_accuracy: 0.9333\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.1442 - accuracy: 0.7669 - val_loss: 0.1242 - val_accuracy: 0.9333\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.1437 - accuracy: 0.7895 - val_loss: 0.1230 - val_accuracy: 0.9333\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1423 - accuracy: 0.8271 - val_loss: 0.1224 - val_accuracy: 0.9333\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1409 - accuracy: 0.8647 - val_loss: 0.1222 - val_accuracy: 0.9333\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1399 - accuracy: 0.8872 - val_loss: 0.1223 - val_accuracy: 0.9778\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1393 - accuracy: 0.9248 - val_loss: 0.1223 - val_accuracy: 0.9556\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.1388 - accuracy: 0.9248 - val_loss: 0.1220 - val_accuracy: 0.9556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x290ea3160>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO fit model\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeper neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hR7AW49wR5rO"
   },
   "source": [
    "Now, we'll try to use a deep neural network to classify the small images in the dataset CIFAR10.  These are small (32x32) color images of 10 categories of things, including cats and airplanes.  You can browse the dataset at: https://knowyourdata-tfds.withgoogle.com/#tab=STATS&dataset=cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Wr0UuEoMRE48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1CU0ddrUqwL"
   },
   "source": [
    "As a baseline, try again fitting the MNIST network at https://keras.io/examples/vision/mnist_convnet/ to this data.  You'll probably benefit from more epochs - try around 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "p4DKF8DYh7cQ"
   },
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSmKRPYNTYG6",
    "outputId": "32a056d6-2517-44b1-b180-f6b5999a40fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 10s 22ms/step - loss: 1.6900 - accuracy: 0.3786 - val_loss: 1.3918 - val_accuracy: 0.5007\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 1.3677 - accuracy: 0.5107 - val_loss: 1.1906 - val_accuracy: 0.5739\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 1.2290 - accuracy: 0.5616 - val_loss: 1.1203 - val_accuracy: 0.6051\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 1.1366 - accuracy: 0.5978 - val_loss: 1.0213 - val_accuracy: 0.6465\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 1.0670 - accuracy: 0.6227 - val_loss: 0.9872 - val_accuracy: 0.6555\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1.0151 - accuracy: 0.6441 - val_loss: 0.9365 - val_accuracy: 0.6741\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.9706 - accuracy: 0.6600 - val_loss: 0.9560 - val_accuracy: 0.6588\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 0.9274 - accuracy: 0.6776 - val_loss: 0.8979 - val_accuracy: 0.6835\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.8913 - accuracy: 0.6895 - val_loss: 0.8682 - val_accuracy: 0.6977\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.8555 - accuracy: 0.7015 - val_loss: 0.8552 - val_accuracy: 0.7029\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.8304 - accuracy: 0.7093 - val_loss: 0.8705 - val_accuracy: 0.6998\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.8012 - accuracy: 0.7187 - val_loss: 0.8686 - val_accuracy: 0.6990\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.7733 - accuracy: 0.7288 - val_loss: 0.8414 - val_accuracy: 0.7089\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.7579 - accuracy: 0.7341 - val_loss: 0.8534 - val_accuracy: 0.7070\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.7295 - accuracy: 0.7445 - val_loss: 0.8362 - val_accuracy: 0.7132\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.7052 - accuracy: 0.7494 - val_loss: 0.8365 - val_accuracy: 0.7164\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.6909 - accuracy: 0.7554 - val_loss: 0.8342 - val_accuracy: 0.7156\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.6684 - accuracy: 0.7643 - val_loss: 0.8297 - val_accuracy: 0.7217\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.6482 - accuracy: 0.7667 - val_loss: 0.8536 - val_accuracy: 0.7145\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.6330 - accuracy: 0.7742 - val_loss: 0.8201 - val_accuracy: 0.7253\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.6129 - accuracy: 0.7824 - val_loss: 0.8505 - val_accuracy: 0.7193\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.6087 - accuracy: 0.7817 - val_loss: 0.8670 - val_accuracy: 0.7171\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.5788 - accuracy: 0.7927 - val_loss: 0.8626 - val_accuracy: 0.7227\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.5718 - accuracy: 0.7935 - val_loss: 0.8470 - val_accuracy: 0.7218\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.5515 - accuracy: 0.8014 - val_loss: 0.9051 - val_accuracy: 0.7121\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.5427 - accuracy: 0.8041 - val_loss: 0.8697 - val_accuracy: 0.7208\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.5238 - accuracy: 0.8119 - val_loss: 0.8747 - val_accuracy: 0.7221\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.5137 - accuracy: 0.8130 - val_loss: 0.9097 - val_accuracy: 0.7174\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.5051 - accuracy: 0.8187 - val_loss: 0.9031 - val_accuracy: 0.7221\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.4913 - accuracy: 0.8205 - val_loss: 0.9520 - val_accuracy: 0.7145\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.4842 - accuracy: 0.8248 - val_loss: 0.8831 - val_accuracy: 0.7279\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.4640 - accuracy: 0.8303 - val_loss: 0.9242 - val_accuracy: 0.7229\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.4576 - accuracy: 0.8330 - val_loss: 0.9126 - val_accuracy: 0.7206\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.4544 - accuracy: 0.8346 - val_loss: 0.9279 - val_accuracy: 0.7229\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.4426 - accuracy: 0.8363 - val_loss: 0.9699 - val_accuracy: 0.7219\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.4372 - accuracy: 0.8384 - val_loss: 0.9482 - val_accuracy: 0.7197\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.4333 - accuracy: 0.8395 - val_loss: 0.9439 - val_accuracy: 0.7221\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.4186 - accuracy: 0.8462 - val_loss: 0.9592 - val_accuracy: 0.7218\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.4066 - accuracy: 0.8489 - val_loss: 0.9958 - val_accuracy: 0.7185\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.4044 - accuracy: 0.8494 - val_loss: 0.9759 - val_accuracy: 0.7210\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3972 - accuracy: 0.8523 - val_loss: 1.0282 - val_accuracy: 0.7232\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3903 - accuracy: 0.8541 - val_loss: 0.9954 - val_accuracy: 0.7197\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3937 - accuracy: 0.8540 - val_loss: 1.0238 - val_accuracy: 0.7238\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3773 - accuracy: 0.8591 - val_loss: 1.0431 - val_accuracy: 0.7236\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3700 - accuracy: 0.8615 - val_loss: 1.0587 - val_accuracy: 0.7183\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3707 - accuracy: 0.8609 - val_loss: 1.0974 - val_accuracy: 0.7191\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3652 - accuracy: 0.8617 - val_loss: 1.1072 - val_accuracy: 0.7174\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3602 - accuracy: 0.8661 - val_loss: 1.1505 - val_accuracy: 0.7165\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3461 - accuracy: 0.8691 - val_loss: 1.0694 - val_accuracy: 0.7231\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3458 - accuracy: 0.8687 - val_loss: 1.1002 - val_accuracy: 0.7181\n"
     ]
    }
   ],
   "source": [
    "# TODO to_categorical, create model, compile model, fit model\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Load the data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Convert class vectors to binary class matrices (for use with categorical_crossentropy)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "saG4F5VOVp9y"
   },
   "source": [
    "Now try to improve the performance by adding another couple of layers, following the pattern of adding successive Conv2D and MaxPooling2D blocks that double the number of filters each time (32, 64, 128...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sgAzlUkVomM",
    "outputId": "68325e87-b8c7-422e-f6fb-f5a48390edf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 13s 31ms/step - loss: 1.7632 - accuracy: 0.3451 - val_loss: 1.4100 - val_accuracy: 0.4821\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 1.4090 - accuracy: 0.4890 - val_loss: 1.2513 - val_accuracy: 0.5516\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1.2481 - accuracy: 0.5554 - val_loss: 1.1453 - val_accuracy: 0.5937\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1.1332 - accuracy: 0.6024 - val_loss: 1.0484 - val_accuracy: 0.6337\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 1.0444 - accuracy: 0.6347 - val_loss: 0.9629 - val_accuracy: 0.6587\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.9634 - accuracy: 0.6629 - val_loss: 0.9069 - val_accuracy: 0.6829\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.9045 - accuracy: 0.6848 - val_loss: 0.9216 - val_accuracy: 0.6803\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.8584 - accuracy: 0.7014 - val_loss: 0.8539 - val_accuracy: 0.7069\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.8150 - accuracy: 0.7188 - val_loss: 0.8448 - val_accuracy: 0.7057\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.7673 - accuracy: 0.7357 - val_loss: 0.8555 - val_accuracy: 0.7068\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.7397 - accuracy: 0.7442 - val_loss: 0.8022 - val_accuracy: 0.7248\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.7031 - accuracy: 0.7564 - val_loss: 0.8182 - val_accuracy: 0.7219\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.6761 - accuracy: 0.7649 - val_loss: 0.8285 - val_accuracy: 0.7176\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.6447 - accuracy: 0.7749 - val_loss: 0.8154 - val_accuracy: 0.7238\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.6149 - accuracy: 0.7864 - val_loss: 0.8017 - val_accuracy: 0.7325\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.5986 - accuracy: 0.7916 - val_loss: 0.8189 - val_accuracy: 0.7234\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.5759 - accuracy: 0.7974 - val_loss: 0.7901 - val_accuracy: 0.7395\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.5584 - accuracy: 0.8056 - val_loss: 0.8406 - val_accuracy: 0.7244\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.5369 - accuracy: 0.8129 - val_loss: 0.8228 - val_accuracy: 0.7318\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.5158 - accuracy: 0.8177 - val_loss: 0.8447 - val_accuracy: 0.7275\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.4944 - accuracy: 0.8269 - val_loss: 0.8273 - val_accuracy: 0.7367\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.4741 - accuracy: 0.8331 - val_loss: 0.8552 - val_accuracy: 0.7282\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.4575 - accuracy: 0.8399 - val_loss: 0.8576 - val_accuracy: 0.7334\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.4411 - accuracy: 0.8442 - val_loss: 0.8732 - val_accuracy: 0.7342\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.4281 - accuracy: 0.8470 - val_loss: 0.8910 - val_accuracy: 0.7342\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.4143 - accuracy: 0.8526 - val_loss: 0.9189 - val_accuracy: 0.7303\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.4008 - accuracy: 0.8587 - val_loss: 0.9206 - val_accuracy: 0.7293\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.3852 - accuracy: 0.8641 - val_loss: 0.8983 - val_accuracy: 0.7374\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.3729 - accuracy: 0.8661 - val_loss: 0.9254 - val_accuracy: 0.7372\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.3660 - accuracy: 0.8694 - val_loss: 0.9603 - val_accuracy: 0.7292\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.3540 - accuracy: 0.8736 - val_loss: 0.9730 - val_accuracy: 0.7332\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.3400 - accuracy: 0.8784 - val_loss: 1.0386 - val_accuracy: 0.7234\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.3305 - accuracy: 0.8814 - val_loss: 1.0327 - val_accuracy: 0.7271\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.3182 - accuracy: 0.8862 - val_loss: 1.0301 - val_accuracy: 0.7364\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 8s 20ms/step - loss: 0.3212 - accuracy: 0.8861 - val_loss: 1.0584 - val_accuracy: 0.7236\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.3013 - accuracy: 0.8912 - val_loss: 1.0974 - val_accuracy: 0.7310\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.2918 - accuracy: 0.8950 - val_loss: 1.0887 - val_accuracy: 0.7298\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.2792 - accuracy: 0.8991 - val_loss: 1.1622 - val_accuracy: 0.7218\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.2805 - accuracy: 0.8980 - val_loss: 1.1357 - val_accuracy: 0.7332\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.2745 - accuracy: 0.9021 - val_loss: 1.2280 - val_accuracy: 0.7121\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.2639 - accuracy: 0.9039 - val_loss: 1.1720 - val_accuracy: 0.7253\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 0.2560 - accuracy: 0.9063 - val_loss: 1.1819 - val_accuracy: 0.7292\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.2522 - accuracy: 0.9081 - val_loss: 1.1974 - val_accuracy: 0.7293\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.2407 - accuracy: 0.9124 - val_loss: 1.2263 - val_accuracy: 0.7283\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.2470 - accuracy: 0.9109 - val_loss: 1.2037 - val_accuracy: 0.7297\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.2283 - accuracy: 0.9178 - val_loss: 1.2370 - val_accuracy: 0.7253\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.2373 - accuracy: 0.9142 - val_loss: 1.2866 - val_accuracy: 0.7226\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 8s 22ms/step - loss: 0.2220 - accuracy: 0.9178 - val_loss: 1.3436 - val_accuracy: 0.7141\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.2316 - accuracy: 0.9170 - val_loss: 1.3310 - val_accuracy: 0.7223\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 8s 21ms/step - loss: 0.2218 - accuracy: 0.9202 - val_loss: 1.3660 - val_accuracy: 0.7270\n"
     ]
    }
   ],
   "source": [
    "# TODO as above but experiment with extra layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),  # Additional Conv2D layer\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=50, validation_data=(x_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R8_NN2_DS340_F22_sol.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
